---
# Olho de Thoth
<div align="center">
  <img src="https://media1.tenor.com/m/DvFsvcuRZC0AAAAd/ra-amun.gif" alt="Olho-de-thoth" height='300px' width='400px'>
</div>

ğŸ§  "O Olho de Thoth vÃª alÃ©m da ilusÃ£o."

Um sistema hÃ­brido para detectar vÃ­deos provavelmente gerados por inteligÃªncia artificial â€” usando anÃ¡lise visual, aprendizado de mÃ¡quina e metadados.

## ğŸŒŸ Sobre

Olho-de-Thoth Ã© uma ferramenta inspirada na sabedoria do deus egÃ­pcio Thoth, capaz de "ver" se um vÃ­deo foi criado por IA ou gravado na vida real. Ele usa tÃ©cnicas avanÃ§adas de visÃ£o computacional, modelos prÃ©-treinados (como XceptionNet), anÃ¡lise de artefatos visuais e leitura de metadados para identificar pistas sutis de vÃ­deos sintÃ©ticos.

Com a explosÃ£o de modelos como Google Veo 3, OpenAI Sora e Stable Video Diffusion, torna-se essencial ter sistemas capazes de distinguir o real do falso. O Olho-de-Thoth nasce dessa necessidade: ser o olho que enxerga a verdade por trÃ¡s da tecnologia.

## ğŸ” Funcionalidades

- âœ… AnÃ¡lise facial: detecta inconsistÃªncias faciais e ausÃªncia de piscadelas
- ğŸ¤– Uso de modelo de IA (XceptionNet) para classificaÃ§Ã£o frame a frame
- ğŸ“¸ DetecÃ§Ã£o de nitidez anormal
- ğŸï¸ AnÃ¡lise de tremor entre frames (jitter)
- ğŸ“Š AnÃ¡lise de frequÃªncia espacial (FFT)
- ğŸ“„ Leitura de metadados do vÃ­deo (via FFmpeg / ffprobe)
- ğŸ§® Sistema de pontuaÃ§Ã£o final para decisÃ£o

## ğŸ§ª Como funciona?

O detector analisa o vÃ­deo em mÃºltiplas camadas:

1. ExtraÃ§Ã£o de frames do vÃ­deo
2. AnÃ¡lise facial e microcomportamentos
3. MediÃ§Ã£o de nitidez e jitter
4. Transformada de Fourier (FFT) para padrÃµes espaciais
5. ClassificaÃ§Ã£o com modelo XceptionNet
6. Leitura de metadados do arquivo
7. AtribuiÃ§Ã£o de pontuaÃ§Ã£o e decisÃ£o final

ğŸ” Se a soma das pistas for maior ou igual a 4 â†’ Provavelmente gerado por IA

## ğŸ“¦ Requisitos

Para rodar localmente:

```bash
pip install opencv-python numpy mediapipe tensorflow ffmpeg-python
```

ğŸ’¡ No Windows, instale tambÃ©m o FFmpeg e adicione ao PATH.

## ğŸš€ Como usar

Clone o repositÃ³rio:

```bash
git clone https://github.com/seu-usuario/Olho-de-Thoth.git 
cd Olho-de-Thoth
```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

Execute:

```bash
python main.py
```

Digite o caminho completo do vÃ­deo quando solicitado:

```bash
Digite o caminho completo do vÃ­deo (ex: ./video.mp4): videos/exemplo.mp4
```

Para Rodar no Google Colab:

1Âº cÃ©lula - bibliotecas
```bash
!pip install numpy==1.23.5
!pip install --upgrade --no-cache-dir mediapipe
!pip install opencv-python-headless
```

2Âº cÃ©lula - cÃ³digo
```bash
copie ou importe o main_colab_google.ipynb
```


## ğŸ“ˆ Exemplo de saÃ­da

```
--- RESULTADO DA ANÃLISE ---
Problemas faciais detectados: 3
Piscadelas detectadas: 0
Nitidez mÃ©dia: 26.32
MÃ©dia de jitter: 4.92
MÃ©dia de frequÃªncia (FFT): 147.07
Probabilidade mÃ©dia de IA: 57.00%
[Pista encontrada nos metadados]: google, lavf

PontuaÃ§Ã£o total de suspeita (limiar: 4): 6
âš ï¸ Resultado: Provavelmente gerado por IA
```

## ğŸ§¬ Tecnologias Usadas

- ğŸ Python 3.x
- ğŸ“¹ OpenCV
- ğŸ§® NumPy
- ğŸ‘ï¸ MediaPipe (FaceMesh)
- ğŸ¤– TensorFlow + Keras
- ğŸ“Š FFT (transformada de Fourier)
- ğŸ“ JSON + FFmpeg

## ğŸ§© Futuras melhorias

- ğŸ“· Adicionar OCR para detectar marcas d'Ã¡gua invisÃ­veis
- ğŸ« Detectar respiraÃ§Ã£o natural
- ğŸ“ Exportar relatÃ³rio em PDF apÃ³s anÃ¡lise
- ğŸ–¥ï¸ Interface grÃ¡fica (Tkinter ou PySide)
- ğŸ“Š Suporte a batch de vÃ­deos

## ğŸ“š ReferÃªncias

- Chollet, F. (2016). Xception: Deep Learning with Depthwise Separable Convolutions
- Rossler, A. et al. (2019). FaceForensics++
- MediaPipe FaceMesh â€“ [GitHub](https://github.com/google/mediapipe)
- FFmpeg Documentation â€“ [FFmpeg](https://ffmpeg.org/)

## ğŸ™ CrÃ©ditos

Desenvolvido por [Davi Mattos].  
InspiraÃ§Ã£o: Thoth, o deus da sabedoria e da verdade.

## ğŸ“Œ LicenÃ§a

MIT License â€“ veja LICENSE para mais informaÃ§Ãµes.

---
